{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# https://scikit-learn.org/stable/modules/permutation_importance.html"
      ],
      "metadata": {
        "id": "WLflqionmsLy"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Misc\n",
        "RANDOM_STATE = 42"
      ],
      "metadata": {
        "id": "Qf-3ShuU6qrS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import joblib # https://stackoverflow.com/questions/56107259/how-to-save-a-trained-model-by-scikit-learn\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_predict, GridSearchCV\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score\n",
        "  )"
      ],
      "metadata": {
        "id": "4jXoCZN4Kf_w"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data splitting"
      ],
      "metadata": {
        "id": "Hmu6BVyTVyD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --fuzzy https://drive.google.com/file/d/17qgFjTIUgxsiURgGjVC6WlEFn6Wl-OeJ/view?usp=sharing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJyR1-82QwUs",
        "outputId": "8a368151-fd4a-4adb-ed6d-8025b15de8e4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=17qgFjTIUgxsiURgGjVC6WlEFn6Wl-OeJ\n",
            "To: /content/cleaned_bmarket.csv\n",
            "\r  0% 0.00/2.65M [00:00<?, ?B/s]\r100% 2.65M/2.65M [00:00<00:00, 27.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"./cleaned_bmarket.csv\")"
      ],
      "metadata": {
        "id": "_-An-SRXU1je"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['Subscription Status']\n",
        "X = df.drop('Subscription Status', axis=1)\n",
        "X = pd.get_dummies(X, drop_first=True) # PLEASE rememeber to research label encoder"
      ],
      "metadata": {
        "id": "qYJsuqp-V5JT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhT2A6tHWcLg",
        "outputId": "7ae5708a-4726-4949-c70e-796d32d29c37"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40787, 26) (40787,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y)"
      ],
      "metadata": {
        "id": "7keKod236Zse"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Misc"
      ],
      "metadata": {
        "id": "0ygf_syPvpUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelWrapper:\n",
        "    def __init__(self, title, model, hyperparameters, param_grid, cv):\n",
        "        self.title = title\n",
        "        self.model = model(**hyperparameters)\n",
        "        self.param_grid = param_grid\n",
        "        self.cv = cv\n",
        "\n",
        "        self.best_epoch = None\n",
        "        self.best_params = None\n",
        "        self.best_model = None\n",
        "\n",
        "    def run_gridsearch(self, X, y):\n",
        "        gs = GridSearchCV(\n",
        "            estimator=self.model,\n",
        "            param_grid=self.param_grid,\n",
        "            cv=self.cv,\n",
        "            scoring='f1', # REMEBR TO OPTIMISE BASED ON CLASS IMBALANCE!!\n",
        "            n_jobs=-1,\n",
        "            verbose=2,\n",
        "            return_train_score=True\n",
        "        )\n",
        "\n",
        "        gs.fit(X, y) # PLSSSS TRAINNNNNN :3\n",
        "\n",
        "        self.best_params = gs.best_params_\n",
        "        self.best_model = gs.best_estimator_\n",
        "        if hasattr(gs.best_estimator_, 'n_estimators'):\n",
        "            self.best_epoch = gs.best_estimator_.n_estimators\n",
        "        else:\n",
        "            self.best_epoch = getattr(gs.best_estimator_, 'n_iter_')\n",
        "\n",
        "    def write_info_to_disk(self, X, y, folder_path):\n",
        "        save_dir = os.path.join(folder_path, self.title)\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "        model_path = os.path.join(save_dir, f\"{self.title}.pkl\")\n",
        "        joblib.dump(self.best_model, model_path)\n",
        "\n",
        "        params_path = os.path.join(save_dir, \"parameters.json\")\n",
        "        with open(params_path, 'w') as f:\n",
        "            json.dump(self.best_params, f, indent=4)\n",
        "\n",
        "        y_pred = self.best_model.predict(X)\n",
        "\n",
        "        cm = confusion_matrix(y, y_pred)\n",
        "\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        ax = sns.heatmap(cm, annot=True, fmt='d')\n",
        "        labels = ['False', 'True']\n",
        "        plt.title(f'Confusion Matrix: {self.title}')\n",
        "        ax.set_xticklabels(labels)\n",
        "        ax.set_yticklabels(labels)\n",
        "        ax.set_ylabel('Actual')\n",
        "        ax.set_xlabel('Predicted')\n",
        "\n",
        "        plot_path = os.path.join(save_dir, \"cmatrix.png\")\n",
        "        plt.savefig(plot_path)\n",
        "        plt.close()\n",
        "\n",
        "        test_error = pd.concat([measure_error(y, y_pred, 'test')], axis=1)\n",
        "        test_error.to_csv(os.path.join(save_dir, \"test_error.csv\"))"
      ],
      "metadata": {
        "id": "zWw1OEW7hDMt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###################\n",
        "# Hyperparameters #\n",
        "###################\n",
        "\n",
        "# Random Forest: {\n",
        "rf_params = {\n",
        "    \"n_jobs\": 1,\n",
        "    \"oob_score\": True,\n",
        "    \"warm_start\": False,\n",
        "    \"random_state\": RANDOM_STATE\n",
        "}\n",
        "\n",
        "rf_gs_params = {\n",
        "    \"max_features\": [\"sqrt\", \"log2\", None],\n",
        "    \"min_samples_split\": [2, 5, 10],\n",
        "    'max_samples': [0.5, 0.75, None,],\n",
        "    \"class_weight\": [\"balanced\", None],\n",
        "    \"max_depth\": [10, 20, None],\n",
        "    \"n_estimators\": [500, 1000, 1500],\n",
        "}\n",
        "# }"
      ],
      "metadata": {
        "id": "UY07MZqVbNe9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def measure_error(y_true, y_pred, label):\n",
        "    return pd.Series({\n",
        "        'accuracy':accuracy_score(y_true, y_pred),\n",
        "        'precision': precision_score(y_true, y_pred),\n",
        "        'recall': recall_score(y_true, y_pred),\n",
        "        'f1': f1_score(y_true, y_pred)},\n",
        "        name=label)"
      ],
      "metadata": {
        "id": "aSdKNzzu3BgD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ensemble models"
      ],
      "metadata": {
        "id": "tKR96oRJKXs9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "-XN7QoTIgMXP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimization Methods**\n",
        "\n",
        "\n",
        "*   Grid Search\n",
        "*   Adjusting decision threshold\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gRuhKsglMtn_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "QKVAhXnfVpcO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_ens = ModelWrapper(\n",
        "    title = \"RandomForestClassifier\",\n",
        "    model = RandomForestClassifier,\n",
        "    hyperparameters = {**rf_params},\n",
        "    param_grid = {**rf_gs_params},\n",
        "    cv = 2\n",
        ")"
      ],
      "metadata": {
        "id": "pRMqJsLllh2A"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clfs = [\n",
        "    rf_ens\n",
        "]"
      ],
      "metadata": {
        "id": "_tRth6U2nry_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORTANT: Remeber to fix for parallel processing in kedro! ^^\n",
        "\n",
        "for model in clfs:\n",
        "    model.run_gridsearch(X_train, y_train)\n",
        "    model.write_info_to_disk(X_test, y_test, \"/content\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoKxc-zsnqh1",
        "outputId": "9ca75db0-a76c-41cb-aa56-5a3c69b4018f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 162 candidates, totalling 324 fits\n"
          ]
        }
      ]
    }
  ]
}